{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T00:58:17.969050Z",
     "start_time": "2019-02-20T00:58:17.949694Z"
    }
   },
   "source": [
    "| Authors:  | Bex Dunn|\n",
    "|----------|----------------|\n",
    "| Created: | Feb 20, 2019 |\n",
    "| Last edited: | Feb 20, 2019 |\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`\n",
    "\n",
    "If you find an error or bug in this notebook, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated notebook back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "__Background:__ Data from the [Landsat](https://landsat.usgs.gov/about-landsat) 5,7 and 8 satellite missions are accessible through [Digital Earth Australia](http://www.ga.gov.au/about/projects/geographic/digital-earth-australia) (DEA). \n",
    "\n",
    "The *Tasseled Cap Index (TCI)* is a method of reducing 6 bands of satellite data (BLUE, GREEN, RED, NIR, SWIR1, SWIR2) to 3 bands (Brightness, Greenness, Wetness) using a Principal Components Analysis and Procrustes' Rotation [(Roberts et al 2018)](##References). This notebook uses the published coefficients of [Crist 1985](##References) as applied to Digital Earth Australia's Landsat satellite data.This notebook produces the wetness index.\n",
    "\n",
    "__What does this notebook do?:__ This notebook takes a supplied shapefile of a polygon and queries the datacube Landsat surface reflectance data. It calculates thresholded tasselled cap wetness. The results are output as geotiff."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`plot`,:index:`gridspec`, :index:`Landsat`,:index:`Landsat5`,:index:`Landsat7`,:index:`Landsat8`, :index:`polygondrill`, :index:`DEAPlotting`, :index:`shapefile`, :index:`geopolygon`, :index:`datacube.utils.geometry`, :index:`fiona`, :index:`rasterio`, :index:`query`,:index:`Scripts`,:index:`tasseled_cap`,                                                                                                           :index:`DEADataHandling`, :index:`DEAPlotting`, :index:`masking`,:index:`make mask`,:index:`load_clearlandsat`:index:`write_geotiff`, :index:`multi_timesteps_geotiffs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.406Z"
    }
   },
   "outputs": [],
   "source": [
    "import datacube\n",
    "import datetime\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "from shapely import geometry\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "from datacube.helpers import ga_pq_fuser, write_geotiff\n",
    "\n",
    "sys.path.append('../10_Scripts')\n",
    "import DEADataHandling, DEAPlotting, TasseledCapTools\n",
    "\n",
    "dc = datacube.Datacube(app='tcw')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.410Z"
    }
   },
   "outputs": [],
   "source": [
    "#change the path here if you want a different polygon\n",
    "#poly_path = '/g/data/r78/rjd547/groundwater_activities/Burdekin/Burdekin_shapefiles/reeves_lake_for_demo.shp'\n",
    "poly_path = '/g/data/r78/rjd547/shapefiles/EnvironmentalFlowMonitoringPolygon.shp'\n",
    "#poly_path = '/g/data/r78/rjd547/shapefiles/FarmScaleWaterBalancePolygon.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.413Z"
    }
   },
   "outputs": [],
   "source": [
    "#open the polygon\n",
    "with fiona.open(poly_path) as shapes:\n",
    "        crs = geometry.CRS(shapes.crs_wkt)\n",
    "        first_geometry = next(iter(shapes))['geometry']\n",
    "        geom = geometry.Geometry(first_geometry, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.415Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot polygon to check it looks ok\n",
    "plt.clf()\n",
    "shape_plot = gpd.read_file(poly_path)\n",
    "shape_plot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.418Z"
    }
   },
   "outputs": [],
   "source": [
    "query = {'geopolygon': geom,\n",
    "         #'time': ('2018-05-01', '2018-07-31')\n",
    "         'time': ('2016-10-01', '2016-10-30')\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set cloudmasking threshold and load landsat nbart data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.423Z"
    }
   },
   "outputs": [],
   "source": [
    "#set cloudmasking threshold and load landsat nbart data\n",
    "landsat_masked_prop = 0 # 0.90\n",
    "ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart', \n",
    "                mask_dict=dict(cloud_acca='no_cloud',\n",
    "                 cloud_shadow_acca='no_cloud_shadow',\n",
    "                 cloud_shadow_fmask='no_cloud_shadow',\n",
    "                 cloud_fmask='no_cloud',\n",
    "                 blue_saturated=False,\n",
    "                 green_saturated=False,\n",
    "                 red_saturated=False,\n",
    "                 nir_saturated=False,\n",
    "                 swir1_saturated=False,\n",
    "                 swir2_saturated=False,\n",
    "                 contiguous=True),\n",
    "                mask_pixel_quality=True,\n",
    "                masked_prop=landsat_masked_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask the data with our original polygon to remove extra data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.426Z"
    }
   },
   "outputs": [],
   "source": [
    "data = ls578_ds\n",
    "mask = rasterio.features.geometry_mask([geom.to_crs(data.geobox.crs)for geoms in [geom]],\n",
    "                                           out_shape=data.geobox.shape,\n",
    "                                           transform=data.geobox.affine,\n",
    "                                           all_touched=False,\n",
    "                                           invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.430Z"
    }
   },
   "outputs": [],
   "source": [
    "#for some reason xarray is not playing nicely with our old masking function\n",
    "mask_xr = xr.DataArray(mask, dims = ('y','x'))\n",
    "ls578_ds = data.where(mask_xr==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.433Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "# DEAPlotting.rgb(ls578_ds, bands=['swir1', 'nir', 'green'], col='time',col_wrap=4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.435Z"
    }
   },
   "outputs": [],
   "source": [
    "#transform the nbart into tci\n",
    "tci = TasseledCapTools.thresholded_tasseled_cap(ls578_ds,wetness_threshold=-1200, drop=True , drop_tc_bands=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.438Z"
    }
   },
   "outputs": [],
   "source": [
    "tcw = tci['wetness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write geotiffs of wetness for each time we have imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.442Z"
    }
   },
   "outputs": [],
   "source": [
    "#get attrs off our original dataset\n",
    "tcw_dataset=tcw.to_dataset()\n",
    "tcw_dataset.attrs=ls578_ds.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up paths to write out outputs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.446Z"
    }
   },
   "outputs": [],
   "source": [
    "#get polygon name from the polygon path\n",
    "polyname = poly_path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.449Z"
    }
   },
   "outputs": [],
   "source": [
    "savefilepath = '/g/data/r78/rjd547/WaterCompHackFeb2019/'+polyname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.453Z"
    }
   },
   "outputs": [],
   "source": [
    "#set dataset equal to wetness dataset\n",
    "ds = tcw_dataset\n",
    "#write a geotiff to file for each timestep\n",
    "if len(ds.time)==1:\n",
    "    print('one timestep')\n",
    "    #drop the time dimension for only one timestep\n",
    "    #write the dataset without the data percentage to file\n",
    "    ds1 = ds.squeeze()\n",
    "    #ds1 = ds1.drop('data_perc')\n",
    "    write_geotiff(savefilepath+'_TCW_'+'.tif', ds1)\n",
    "\n",
    "elif len(ds.time)>1:\n",
    "    print('multiple timesteps') \n",
    "    #remove data percentage as it breaks the geotiff writer\n",
    "    #ds = ds.drop('data_perc')\n",
    "    for timestep in range(len(ds.time)):\n",
    "        timestep_date =np.datetime_as_string(ds.time.isel(time=timestep))[0:10]\n",
    "        try:\n",
    "            write_geotiff(savefilepath+'_TCW_'+timestep_date+'.tif', ds.isel(time =timestep))\n",
    "            #complain if the file already exists but don't fail    \n",
    "            print('wrote to GeoTIFF' )\n",
    "        except RuntimeError as err:\n",
    "            print(\"RuntimeError: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write geotiffs of thresholded wetness for each time we have imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.457Z"
    }
   },
   "outputs": [],
   "source": [
    "#get attrs off our original dataset\n",
    "tcw_thresholded = tci['wetness_thresholded']\n",
    "tcw_thresholded_dataset=tcw_thresholded.to_dataset()\n",
    "tcw_thresholded_dataset.attrs=ls578_ds.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB threshold here is hardcoded into filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.460Z"
    }
   },
   "outputs": [],
   "source": [
    "#set dataset equal to thresholded wetness dataset\n",
    "ds = tcw_thresholded_dataset\n",
    "#write a geotiff to file for each timestep\n",
    "if len(ds.time)==1:\n",
    "    print('one timestep')\n",
    "    #drop the time dimension for only one timestep\n",
    "    #write the dataset without the data percentage to file\n",
    "    ds1 = ds.squeeze()\n",
    "    #ds1 = ds1.drop('data_perc')\n",
    "    write_geotiff(savefilepath+'_TCW-1200_'+'.tif', ds1)\n",
    "\n",
    "elif len(ds.time)>1:\n",
    "    print('multiple timesteps') \n",
    "    #remove data percentage as it breaks the geotiff writer\n",
    "    #ds = ds.drop('data_perc')\n",
    "    for timestep in range(len(ds.time)):\n",
    "        timestep_date =np.datetime_as_string(ds.time.isel(time=timestep))[0:10]\n",
    "        try:\n",
    "            write_geotiff(savefilepath+'_TCW-1200_'+timestep_date+'.tif', ds.isel(time =timestep))\n",
    "            #complain if the file already exists but don't fail    \n",
    "            print('wrote to GeoTIFF' )\n",
    "        except RuntimeError as err:\n",
    "            print(\"RuntimeError: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write geotiffs of surface reflectance for each time we have imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.463Z"
    }
   },
   "outputs": [],
   "source": [
    "for timestep in range(len(ds.time)):\n",
    "    print(np.datetime_as_string(ds.time.isel(time=timestep))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-20T05:14:20.468Z"
    }
   },
   "outputs": [],
   "source": [
    "#set dataset equal to landsat dataset\n",
    "ds = ls578_ds\n",
    "#write a geotiff to file for each timestep\n",
    "if len(ds.time)==1:\n",
    "    print('one timestep')\n",
    "    #drop the time dimension for only one timestep\n",
    "    #write the dataset without the data percentage to file\n",
    "    ds1 = ds.squeeze()\n",
    "    #ds1 = ds1.drop('data_perc')\n",
    "    write_geotiff(savefilepath+'_LS_'+'.tif', ds1)\n",
    "\n",
    "elif len(ds.time)>1:\n",
    "    print('multiple timesteps') \n",
    "    #remove data percentage as it breaks the geotiff writer\n",
    "    #ds = ds.drop('data_perc')\n",
    "    for timestep in range(len(ds.time)):\n",
    "        timestep_date =np.datetime_as_string(ds.time.isel(time=timestep))[0:10]\n",
    "        try:\n",
    "            write_geotiff(savefilepath+'_LS_'+timestep_date+'.tif', ds.isel(time =timestep))\n",
    "            #complain if the file already exists but don't fail    \n",
    "            print('wrote to GeoTIFF' )\n",
    "        except RuntimeError as err:\n",
    "            print(\"RuntimeError: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Roberts, D., Dunn,B., Mueller, N. 2018, *Open Data Cube Products Using High-Dimensional Statistics of Time Series*, in press.\n",
    "\n",
    "2. E. P. Crist, *A tm tasseled cap equivalent transformation for reflectance\n",
    "factor data*, Remote Sensing of Environment, vol. 17, no. 3, pp. 301-306, 1985."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
