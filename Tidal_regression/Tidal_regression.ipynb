{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidal regression\n",
    "\n",
    "**What does this notebook do?** \n",
    "\n",
    "This notebook uses the ([OSU Tidal Prediction Software or OTPS](http://volkov.oce.orst.edu/tides/otps.html)) to tidally tag a time series of Landsat imagery, and then compute pixel-wise regression based on NDWI values.\n",
    "\n",
    "**Requirements:** \n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`\n",
    "\n",
    "`module load otps`\n",
    "\n",
    "If you find an error or bug in this notebook, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated notebook back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "**Date:** August 2018\n",
    "\n",
    "**Authors:** Robbi Bishop-Taylor, Bex Dunn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`tidal_model`, :index:`OTPS`, :index:`tidal_tagging`, :index:`predict_tide`, :index:`composites`, :index:`datacube.utils.geometry`, :index:`dask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:57:50.779247Z",
     "start_time": "2018-08-31T00:57:50.083617Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (DEADataHandling.py, line 399)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/g/data/v10/public/modules/dea-env/20180728/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2963\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-e5e454b60f37>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import DEADataHandling\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../10_Scripts/DEADataHandling.py\"\u001b[0;36m, line \u001b[0;32m399\u001b[0m\n\u001b[0;31m    <<<<<<< HEAD\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from otps import TimePoint\n",
    "from otps import predict_tide\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "\n",
    "# Import external functions from dea-notebooks using relative link to Scripts\n",
    "sys.path.append('../10_Scripts')\n",
    "import DEAPlotting\n",
    "import DEADataHandling\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Create datacube instance\n",
    "dc = datacube.Datacube(app='Tidal regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import remotely-sensed time series data\n",
    "Imports a time series of Landsat observations as a DEA `xarray` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:53:13.168514Z",
     "start_time": "2018-08-31T00:53:13.121099Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DEADataHandling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7b8a2f5a1199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Import data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m data = DEADataHandling.load_clearlandsat(dc=dc, query=query, sensors=['ls5', 'ls7', 'ls8'],\n\u001b[0m\u001b[1;32m     24\u001b[0m                                          \u001b[0mbands_of_interest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'swir1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                          mask_dict=mask_dict, masked_prop=0.8, apply_mask=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEADataHandling' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up analysis data query using \n",
    "lat, lon, buffer = -12.463, 130.885, 3500\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),         \n",
    "         'crs': 'EPSG:3577',\n",
    "         'time': ('1987-01-01', '2018-06-30')}\n",
    "\n",
    "# Mask used to identify bad pixels\n",
    "mask_dict = {'cloud_acca': 'no_cloud', \n",
    "             'cloud_fmask': 'no_cloud', \n",
    "             'cloud_shadow_acca':'no_cloud_shadow',\n",
    "             'cloud_shadow_fmask':'no_cloud_shadow',\n",
    "             'blue_saturated':False,\n",
    "             'green_saturated':False,\n",
    "             'red_saturated':False,\n",
    "             'nir_saturated':False,\n",
    "             'swir1_saturated':False,\n",
    "             'swir2_saturated':False,\n",
    "             'contiguous': True}\n",
    "\n",
    "# Import data\n",
    "data = DEADataHandling.load_clearlandsat(dc=dc, query=query, sensors=['ls5', 'ls7', 'ls8'],\n",
    "                                         bands_of_interest=['swir1', 'nir', 'green'],\n",
    "                                         mask_dict=mask_dict, masked_prop=0.8, apply_mask=True)\n",
    "\n",
    "# Plot data\n",
    "data[['swir1', 'nir', 'green']].isel(time=6).to_array().plot.imshow(robust=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidal modelling using OTPS\n",
    "and extracts a list of timestamps based on the time and date of acquisition for each Landsat observation. These timestamps can then be used as one of the inputs to the [OSU Tidal Prediction Software (OTPS) tidal model](http://volkov.oce.orst.edu/tides/otps.html) to compute tidal heights at the time of acquisition of each Landsat observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:53:08.023703Z",
     "start_time": "2018-08-31T00:53:07.087931Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3a2734f3e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract list of datetimes based on Landsat time of acquisition for each image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobserved_datetimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'M8[s]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Set a tide post: this is the location the OTPS model uses to compute tides for the supplied datetimes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtidepost_lat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtidepost_lon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m12.48315\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m130.85540\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract list of datetimes based on Landsat time of acquisition for each image\n",
    "observed_datetimes = data.time.data.astype('M8[s]').astype('O').tolist()\n",
    "\n",
    "#Set a tide post: this is the location the OTPS model uses to compute tides for the supplied datetimes\n",
    "tidepost_lat, tidepost_lon = -12.48315, 130.85540\n",
    "\n",
    "# The OTPS model requires inputs as 'TimePoint' objects, which are combinations of lon-lat coordinates \n",
    "# and a datetime object. You can create a list of these with a list comprehension:\n",
    "observed_timepoints = [TimePoint(tidepost_lon, tidepost_lat, dt) for dt in observed_datetimes]\n",
    "\n",
    "# Feed the entire list of timepoints to the OTPS `predict_tide` function:\n",
    "observed_predictedtides = predict_tide(observed_timepoints)\n",
    "\n",
    "# For each of the predicted tide objects, extract a list of tidal heights in `m` units relative to mean \n",
    "# sea level (the `tide_m` method should not be confused with the `depth_m` method, which gives you the \n",
    "# ocean depth at the tide post location that is used by the OTPS model to predict tides)\n",
    "observed_tideheights = [predictedtide.tide_m for predictedtide in observed_predictedtides]\n",
    "\n",
    "# Create a dataframe of tidal heights for each Landsat observation\n",
    "observed_df = pd.DataFrame({'tide_height': observed_tideheights}, \n",
    "                           index=pd.DatetimeIndex(observed_datetimes))\n",
    "\n",
    "# Plot tidal heights against Landsat observation date\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.scatter(observed_df.index, observed_df.tide_height, linewidth=0.6, zorder=1, label='Modelled')\n",
    "ax.set_title('Landsat observations by tidal height (m)')\n",
    "ax.set_ylabel('Tide height (m)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging, filtering and compositing Landsat observations by tidal height/stage\n",
    "Adds tidal height data back into our original `xarray` dataset so that each Landsat observation is correctly tagged with its corresponding tidal height. Tagged images can then be filtered or composited to study characteristics of the coastline at various tidal stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tide_heights'] = xr.DataArray(observed_tideheights, [('time', data.time)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MNDWI for all timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:       (time: 244, x: 281, y: 281)\n",
       "Coordinates:\n",
       "  * y             (y) float64 -1.312e+06 -1.312e+06 -1.312e+06 -1.312e+06 ...\n",
       "  * x             (x) float64 -1.269e+05 -1.269e+05 -1.268e+05 -1.268e+05 ...\n",
       "  * time          (time) datetime64[ns] 1987-05-30T00:47:23 ...\n",
       "Data variables:\n",
       "    swir1         (time, y, x) float64 2.985e+03 3.072e+03 2.75e+03 ...\n",
       "    nir           (time, y, x) float64 2.429e+03 2.384e+03 2.448e+03 ...\n",
       "    green         (time, y, x) float64 1.635e+03 1.503e+03 1.186e+03 ...\n",
       "    data_perc     (time, y, x) float64 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 ...\n",
       "    tide_heights  (time) float64 1.986 -0.626 -1.399 2.836 2.682 2.854 ...\n",
       "    mndwi         (time, y, x) float64 -0.2922 -0.343 -0.3974 -0.3869 ...\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mndwi'] = (data.green - data.swir1) / (data.green + data.swir1)\n",
    "data\n",
    "# mndwi.plot(col='time', col_wrap=6, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
