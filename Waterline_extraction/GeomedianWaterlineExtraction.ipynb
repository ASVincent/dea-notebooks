{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract annual geomedian waterlines across time\n",
    "**What does this notebook do?** \n",
    "\n",
    "This notebooks demonstrates how to extract waterline contours from the geomedian composite layers for each year. \n",
    "\n",
    "**Requirements:** \n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea/20180515`  *(currently using an older version of `dea` due to a bug in `xr.concat`; will be reverted to `module load dea` in future)*\n",
    "\n",
    "If you find an error or bug in this notebook, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated notebook back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "**Date:** September 2018\n",
    "\n",
    "**Author:** Robbi Bishop-Taylor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`tidal_model`, :index:`OTPS`, :index:`tidal_tagging`, :index:`predict_tide`, :index:`composites`, :index:`dask`, :index:`write_geotiff`,  :index:`filmstrip_plot`, :index:`geopandas`, :index:`point_in_polygon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datacube\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.helpers import write_geotiff\n",
    "from shapely.geometry import Point\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "sys.path.append('../10_Scripts')\n",
    "import SpatialTools\n",
    "\n",
    "# For nicer notebook plotting, hide warnings (comment out for real analysis)\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Create datacube instance\n",
    "dc = datacube.Datacube(app='Tidal geomedian filmstrips')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geomedian filmstrip parameters\n",
    "Set the area, time period  and sensors of interest, and tide limits and epoch length used to produce each geomedian composite. This is the only cell that needs to be edited to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up centre of study area and buffer size in metres for data extraction\n",
    "study_area = 'hume'  # name used as prefix for output files\n",
    "lat, lon = -36.100, 147.210  # centre of study area\n",
    "buffer = 22000  # metre units to extend region of interest on each side of centre point\n",
    "\n",
    "study_area = 'warragamba'  # name used as prefix for output files\n",
    "lat, lon = -34.0124387269, 150.388624121  # centre of study area\n",
    "buffer = 18000  # metre units to extend region of interest on each side of centre point\n",
    "\n",
    "\n",
    "# Set up query\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),\n",
    "         'crs': 'EPSG:3577'}\n",
    "\n",
    "# If output data and figure directories doesn't exist, create them\n",
    "if not os.path.isdir('output_data/{}/'.format(study_area)):\n",
    "    os.makedirs('output_data/{}/'.format(study_area))\n",
    "    \n",
    "if not os.path.isdir('figures/{}/'.format(study_area)):\n",
    "    os.makedirs('figures/{}/'.format(study_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine multiple sensors, load data and generate geomedians\n",
    "For each epoch, combine all sensors into one dataset, load the data for the first time using `dask`'s `.compute()`, then composite all timesteps into a single array using a geometric median computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_dict = {'ls5': ('1987-01-01', '2018-01-01'),\n",
    "#             'ls7': ('1987-01-01', '2003-05-30'),\n",
    "#             'ls8': ('1987-01-01', '2018-01-01')}\n",
    "\n",
    "import datacube\n",
    "dc = datacube.Datacube(app='Annual geomedians')\n",
    "    \n",
    "# Return observations matching query without actually loading them using dask\n",
    "sensor_ls5 = dc.load(product = 'ls5_nbart_geomedian_annual', \n",
    "                     time=('1987-01-01', '2018-01-01'),\n",
    "                     **query)\n",
    "\n",
    "# Return observations matching query without actually loading them using dask\n",
    "sensor_ls7 = dc.load(product = 'ls7_nbart_geomedian_annual', \n",
    "                     time=('1987-01-01', '2002-01-01'),\n",
    "                     **query)\n",
    "\n",
    "# Return observations matching query without actually loading them using dask\n",
    "sensor_ls8 = dc.load(product = 'ls8_nbart_geomedian_annual', \n",
    "                     time=('1987-01-01', '2018-01-01'),\n",
    "                     **query)\n",
    "\n",
    "sensor_all = xr.concat([sensor_ls5, sensor_ls7, sensor_ls8], dim='time')# .median(dim='time', keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 27, x: 1441, y: 1441)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -3.816e+06 -3.816e+06 ... -3.852e+06 -3.852e+06\n",
       "  * x        (x) float64 1.666e+06 1.666e+06 1.666e+06 ... 1.702e+06 1.702e+06\n",
       "  * time     (time) datetime64[ns] 1988-01-01 1989-01-01 ... 2017-01-01\n",
       "Data variables:\n",
       "    blue     (time, y, x) float64 243.0 268.0 287.0 300.0 ... 484.0 494.0 456.0\n",
       "    green    (time, y, x) float64 343.0 367.0 391.0 402.0 ... 803.0 823.0 773.0\n",
       "    red      (time, y, x) float64 337.0 367.0 407.0 427.0 ... 884.0 905.0 849.0\n",
       "    nir      (time, y, x) float64 1.812e+03 1.758e+03 ... 3.713e+03 3.587e+03\n",
       "    swir1    (time, y, x) float64 1.159e+03 1.204e+03 ... 3.078e+03 2.904e+03\n",
       "    swir2    (time, y, x) float64 514.0 600.0 670.0 ... 1.727e+03 1.603e+03\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_combined = xr.concat([sensor_ls5, sensor_ls7, sensor_ls8], dim='time')# .median(dim='time', keep_attrs=True)\n",
    "sensor_combined = sensor_combined.groupby('time').median(dim='time', keep_attrs=True)\n",
    "sensor_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_combined[\"ndwi\"] = (sensor_all.green - sensor_combined.swir1) / (sensor_combined.green + sensor_combined.swir1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract waterlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1988.shp\n",
      "1989\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1989.shp\n",
      "1990\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1990.shp\n",
      "1991\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1991.shp\n",
      "1992\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1992.shp\n",
      "1993\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1993.shp\n",
      "1994\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1994.shp\n",
      "1995\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1995.shp\n",
      "1996\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1996.shp\n",
      "1997\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1997.shp\n",
      "1998\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1998.shp\n",
      "1999\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_1999.shp\n",
      "2000\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2000.shp\n",
      "2001\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2001.shp\n",
      "2002\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2002.shp\n",
      "2004\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2004.shp\n",
      "2005\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2005.shp\n",
      "2006\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2006.shp\n",
      "2007\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2007.shp\n",
      "2009\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2009.shp\n",
      "2010\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2010.shp\n",
      "2011\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2011.shp\n",
      "2013\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2013.shp\n",
      "2014\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2014.shp\n",
      "2015\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2015.shp\n",
      "2016\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2016.shp\n",
      "2017\n",
      "Extracting contour 0\n",
      "\n",
      "Exporting contour shapefile to output_data/warragamba/warragamba_2017.shp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988</td>\n",
       "      <td>66</td>\n",
       "      <td>(LINESTRING (1674803.717483164 -3851537.5, 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1989</td>\n",
       "      <td>66</td>\n",
       "      <td>(LINESTRING (1674787.229509162 -3851537.5, 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1990</td>\n",
       "      <td>69</td>\n",
       "      <td>(LINESTRING (1667187.5 -3815567.510080902, 166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991</td>\n",
       "      <td>66</td>\n",
       "      <td>(LINESTRING (1675162.5 -3815562.942288791, 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992</td>\n",
       "      <td>68</td>\n",
       "      <td>(LINESTRING (1670866.622832209 -3815537.5, 167...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date  area                                           geometry\n",
       "1   1988    66  (LINESTRING (1674803.717483164 -3851537.5, 167...\n",
       "16  1989    66  (LINESTRING (1674787.229509162 -3851537.5, 167...\n",
       "10  1990    69  (LINESTRING (1667187.5 -3815567.510080902, 166...\n",
       "3   1991    66  (LINESTRING (1675162.5 -3815562.942288791, 167...\n",
       "4   1992    68  (LINESTRING (1670866.622832209 -3815537.5, 167..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = sensor_combined.time\n",
    "\n",
    "for year in years:    \n",
    "\n",
    "    ndwi = sensor_combined.sel(time=year)\n",
    "    date = year.dt.year.item()\n",
    "    print(date) \n",
    "    \n",
    "    # Compute area\n",
    "    area = ((ndwi.ndwi > 0).sum() * (25 * 25) / (1000 * 1000)).item()\n",
    "    \n",
    "    # Prepare attributes as input to contour extract\n",
    "    attribute_data = {'date': [date], 'area': [area]}\n",
    "    attribute_dtypes = {'date': 'int', 'area': 'int'}\n",
    "    \n",
    "    # Extract contours with custom attribute fields:\n",
    "    contour_dict = SpatialTools.contour_extract(z_values=[0],\n",
    "                                   ds_array=ndwi.ndwi,\n",
    "                                   ds_crs='epsg:3577',\n",
    "                                   ds_affine=ndwi.geobox.transform,\n",
    "                                   output_shp=f'output_data/{study_area}/{study_area}_{date}.shp',\n",
    "                                   attribute_data=attribute_data,\n",
    "                                   attribute_dtypes=attribute_dtypes)\n",
    "    \n",
    "# Combine all shapefiles into one file\n",
    "import glob\n",
    "shapefiles = glob.glob(f'output_data/{study_area}/{study_area}_*.shp')\n",
    "gdf = pd.concat([gpd.read_file(shp) for shp in shapefiles], sort=False).pipe(gpd.GeoDataFrame)\n",
    "\n",
    "# Save as combined shapefile\n",
    "gdf = gdf.reset_index()[['date', 'area', 'geometry']].sort_values('date')\n",
    "gdf.crs = 'epsg:3577'\n",
    "gdf.to_file(f'output_data/{study_area}/{study_area}_combined.shp')\n",
    "\n",
    "gdf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datacube\n",
    "# dc = datacube.Datacube(app='Annual geomedians')\n",
    "    \n",
    "# # Return observations matching query \n",
    "# sensor_ls5 = dc.load(product = 'ls5_nbart_geomedian_annual', \n",
    "#                      time=('1987-01-01', '2018-01-01'),\n",
    "#                      x=(1343834.550438912, 1389834.550438912),\n",
    "#                      y=(-4048783.3089217427, -4002783.3089217427),\n",
    "#                      crs='EPSG:3577')\n",
    "\n",
    "# # Compute NDVI\n",
    "# sensor_ls5['ndvi'] = (sensor_ls5.nir - sensor_ls5.red)/(sensor_ls5.nir + sensor_ls5.red)\n",
    "# sensor_ls5['mndwi'] = (sensor_ls5.green - sensor_ls5.swir1)/(sensor_ls5.green + sensor_ls5.swir1)\n",
    "\n",
    "# # Find index of min NDVI, and use to pull out all other band values for that timestep\n",
    "# inds = sensor_ls5.mndwi.argmin(dim='time')\n",
    "# min_composite = sensor_ls5.isel(time=inds)\n",
    "\n",
    "# # Find index of max NDVI, and use to pull out all other band values for that timestep\n",
    "# inds = sensor_ls5.mndwi.argmax(dim='time')\n",
    "# max_composite = sensor_ls5.isel(time=inds)\n",
    "\n",
    "# # Plot\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# min_composite[['red', 'green', 'blue']].to_array().plot.imshow(robust=True, ax=axes[0])\n",
    "# max_composite[['red', 'green', 'blue']].to_array().plot.imshow(robust=True, ax=axes[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datacube\n",
    "# from datacube.utils import geometry\n",
    "# from datacube.utils.geometry import CRS\n",
    "\n",
    "# dc = datacube.Datacube(config='/home/561/rt1527/unpublished_products.conf')\n",
    "# dc.list_products()\n",
    "\n",
    "# # Set up centre of area to analyse, and a buffer in metres around this centrepoint\n",
    "# lat, lon, buffer_m, name = -17.6080348351, 139.80119891, 5000, 'mangrove_test'\n",
    "# time_range = ('1987-01-01', '1987-09-01')\n",
    "# resolution = (-25, 25)\n",
    "\n",
    "# x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "# query = {'x': (x - buffer_m - 3000, x + buffer_m + 3000),\n",
    "#          'y': (y - buffer_m, y + buffer_m),    \n",
    "#          'time': time_range,\n",
    "#          'crs': 'EPSG:3577',\n",
    "#          'output_crs': 'EPSG:3577',\n",
    "#          'resolution': resolution} \n",
    "\n",
    "# test = dc.load(product=\"mangrove_extent_cover_albers\", **query)\n",
    "# test\n",
    "\n",
    "# # import DEAPlotting\n",
    "# # DEAPlotting.animated_timeseries(ds=test.isel(time=[1, 5, 10]),\n",
    "# #                                 output_path=f'animated_timeseries_{name}.gif',\n",
    "# #                                 bands=['canopy_cover_class'],\n",
    "# #                                 interval=500,\n",
    "# #                                 width_pixels=1000,\n",
    "# #                                 percentile_stretch=[0.0, 1.0],\n",
    "# #                                 show_date=False,\n",
    "# #                                 onebandplot_kwargs={'cmap':'jet'},\n",
    "# # #                                 onebandplot_cbar = False,\n",
    "# #                                 title=test.time.dt.year.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
